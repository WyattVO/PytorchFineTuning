# ğŸ§  PyTorch Fine-Tuning: ResNet18 on CIFAR-10

Using **PyTorch**, this project demonstrates **transfer learning** by freezing all layers of a pretrained **ResNet18** model (trained on ImageNet) except for the final fully connected layer.  
Only the last layer is retrained for a few epochs on the **CIFAR-10** dataset, which contains 10 classes such as airplanes, cars, and birds.

---

## ğŸš€ Project Summary

- **Model:** `ResNet18 (pretrained on ImageNet)`
- **Dataset:** `CIFAR-10`
- **Method:** Freeze all convolutional layers â†’ retrain final layer
- **Optimizer:** `SGD (lr = 0.01, momentum = 0.9)`
- **Epochs:** 5
- **Results:** Validation accuracy stabilized around **78â€“79%**, showing consistent learning and a well-generalized model.

---

## ğŸ“ˆ Validation Accuracy Over Epochs

<p align="center">
  <img width="437" height="770" alt="Validation Accuracy Plot"
       src="https://github.com/user-attachments/assets/18cbe212-788d-4191-ad86-1e448783f25d" />
</p>

---

## ğŸ§© Key Takeaways

âœ… Transfer learning allows strong performance even with minimal training.  
âœ… Freezing pretrained layers speeds up training dramatically.  
âœ… Accuracy stability (~78-79%) indicates the model generalizes well without overfitting.

---

## ğŸ› ï¸ How to Run

```bash
# 1ï¸âƒ£ Install dependencies
pip install torch torchvision matplotlib

# 2ï¸âƒ£ Run the training script
python train_finetune.py
